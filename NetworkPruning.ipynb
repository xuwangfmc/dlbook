{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "NetworkPruning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xuwangfmc/dlbook/blob/main/NetworkPruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a290f49d"
      },
      "source": [
        "# NetworkPruning\n",
        "   现有许多工作为了追求高精度，通过会设计参数量与复杂度较高的模型，但是这种模型是存在大量信息冗余的。网络剪枝就是针对这一现象，将大量的冗余信息给去掉。\n",
        "网络剪枝主要分为Non-structured Pruning(Wight)和Structured Pruning(Neuron)两种。前者比较灵活，可任意裁各Filter内的参数，参数减少空间较大，精度降低较少，但是这种任意裁剪的方式不利于硬件实现，因为硬件通常是直接进行矩阵运算，额外的复杂操作会使得硬件难以优化；Stuctured Pruning是去掉整个neuron，即整个Filter，参数减少空间较小，精度下降较多，但是硬件支持良好。\n",
        "![NetworkPruning.png](https://s2.loli.net/2022/01/22/aoyRDLGxrf8b67z.png)\n",
        "\n",
        "该教程主要介绍如何使用Pytorch自带的剪枝库对模型进行剪枝，以及实际运用中如何对模型进行剪枝。"
      ],
      "id": "a290f49d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 实验流程"
      ],
      "metadata": {
        "id": "cajO56_ouIgb"
      },
      "id": "cajO56_ouIgb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b55d7b1"
      },
      "source": [
        "\n",
        "**裁剪单个Module**\n",
        "\n"
      ],
      "id": "6b55d7b1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "530bf90e"
      },
      "source": [
        "\n",
        "在进行剪枝之前，先构建LeNet模型。"
      ],
      "id": "530bf90e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cedcc066"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__() \n",
        "        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = LeNet().to(device=device)"
      ],
      "id": "cedcc066",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "023b94ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1fc73a-ba5e-4d34-9ac7-0ee02b7a3fa5"
      },
      "source": [
        "module = model.conv1\n",
        "print(list(module.named_parameters()))"
      ],
      "id": "023b94ef",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('weight', Parameter containing:\n",
            "tensor([[[[-0.3138,  0.2117, -0.3179],\n",
            "          [-0.1768,  0.0209, -0.3088],\n",
            "          [ 0.1922,  0.1970, -0.3047]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3054,  0.2523, -0.0929],\n",
            "          [ 0.3087,  0.3270, -0.1836],\n",
            "          [ 0.1698,  0.2943,  0.3102]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0307,  0.2844, -0.0396],\n",
            "          [ 0.2084, -0.1057,  0.0373],\n",
            "          [ 0.1042, -0.2758, -0.1900]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1137, -0.1251,  0.2503],\n",
            "          [ 0.1387, -0.0317, -0.1184],\n",
            "          [-0.2504,  0.1400,  0.2995]]],\n",
            "\n",
            "\n",
            "        [[[-0.2898, -0.3211, -0.3013],\n",
            "          [ 0.1735, -0.1554,  0.0403],\n",
            "          [ 0.2877, -0.2073,  0.0639]]],\n",
            "\n",
            "\n",
            "        [[[-0.2566, -0.1833,  0.2502],\n",
            "          [-0.2506,  0.1780,  0.2193],\n",
            "          [-0.2474, -0.0557, -0.1214]]]], device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
            "tensor([-0.2063, -0.0221,  0.0029,  0.3152,  0.2007,  0.1731], device='cuda:0',\n",
            "       requires_grad=True))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a99e7721"
      },
      "source": [
        " named_parameters是torch.nn.Module类提供的获取可学习参数的方法,将会返回一个list，其中包括有Weights和bias的初始值。"
      ],
      "id": "a99e7721"
    },
    {
      "cell_type": "markdown",
      "source": [
        "如果我们想要裁剪一个Module，首先我们需要选取一个pruning的方案，目前torch.nn.utils.prune中已经支持  \n",
        "- RandomUnstructured  \n",
        "- L1Unstructured  \n",
        "- RandomStructured  \n",
        "- LnStructured  \n",
        "- CustomFromMask \n",
        " \n",
        "也可以通过继承BasePruningMethod来自定义pruning的方法。"
      ],
      "metadata": {
        "id": "MDgCv52PxS_C"
      },
      "id": "MDgCv52PxS_C"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "455f3977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a990a3e1-8146-4306-dd6b-183db94c74ef"
      },
      "source": [
        "prune.random_unstructured(module,name=\"weight\",amount=0.3)"
      ],
      "id": "455f3977",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3018597"
      },
      "source": [
        "然后我们指定module以及需要pruning的参数的name,最后使用合适的参数，指定pruning的参数。在上述代码中，我们将随机裁剪30%的连接（conv1中weights参数30%的连接）。其中name用于指定module中的某个parameter，amount用于执行需要裁剪连接的比例（0.0到1.0）或者直接给定一个绝对值。"
      ],
      "id": "c3018597"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b9a6046",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3b48bc-aac8-4c4c-eb5b-2a6143e668f9"
      },
      "source": [
        "print(list(module.named_parameters()))"
      ],
      "id": "6b9a6046",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('bias', Parameter containing:\n",
            "tensor([-0.2063, -0.0221,  0.0029,  0.3152,  0.2007,  0.1731], device='cuda:0',\n",
            "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
            "tensor([[[[-0.3138,  0.2117, -0.3179],\n",
            "          [-0.1768,  0.0209, -0.3088],\n",
            "          [ 0.1922,  0.1970, -0.3047]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3054,  0.2523, -0.0929],\n",
            "          [ 0.3087,  0.3270, -0.1836],\n",
            "          [ 0.1698,  0.2943,  0.3102]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0307,  0.2844, -0.0396],\n",
            "          [ 0.2084, -0.1057,  0.0373],\n",
            "          [ 0.1042, -0.2758, -0.1900]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1137, -0.1251,  0.2503],\n",
            "          [ 0.1387, -0.0317, -0.1184],\n",
            "          [-0.2504,  0.1400,  0.2995]]],\n",
            "\n",
            "\n",
            "        [[[-0.2898, -0.3211, -0.3013],\n",
            "          [ 0.1735, -0.1554,  0.0403],\n",
            "          [ 0.2877, -0.2073,  0.0639]]],\n",
            "\n",
            "\n",
            "        [[[-0.2566, -0.1833,  0.2502],\n",
            "          [-0.2506,  0.1780,  0.2193],\n",
            "          [-0.2474, -0.0557, -0.1214]]]], device='cuda:0', requires_grad=True))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e821313"
      },
      "source": [
        "这时候我们会看到weight_orig，和之前打印的数值是没有变化的，但是weights的参数不见了。"
      ],
      "id": "4e821313"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b11e56f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78cf2fde-ea95-46a3-8310-5fc856a5ef84"
      },
      "source": [
        "print(list(module.named_buffers()))"
      ],
      "id": "b11e56f7",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('weight_mask', tensor([[[[0., 0., 1.],\n",
            "          [0., 0., 0.],\n",
            "          [1., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 0.],\n",
            "          [0., 1., 1.],\n",
            "          [1., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 0.],\n",
            "          [1., 1., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 0.],\n",
            "          [0., 1., 0.],\n",
            "          [1., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.],\n",
            "          [0., 1., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 1.],\n",
            "          [1., 0., 0.],\n",
            "          [0., 0., 0.]]]], device='cuda:0'))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48ac8a4f"
      },
      "source": [
        "此时会产生一个weight_mask的掩码，本身不会直接作用于模型，会产生一个weight的属性，这时候原module是不存在weight的parameter,仅仅是一个attribute."
      ],
      "id": "48ac8a4f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b3caaf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d263f2b-733d-483f-b867-a72012de6ddf"
      },
      "source": [
        "print(module.weight)"
      ],
      "id": "7b3caaf0",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.0000,  0.0000, -0.3179],\n",
            "          [-0.0000,  0.0000, -0.0000],\n",
            "          [ 0.1922,  0.0000, -0.3047]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3054,  0.2523, -0.0000],\n",
            "          [ 0.0000,  0.3270, -0.1836],\n",
            "          [ 0.1698,  0.0000,  0.3102]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0307,  0.0000, -0.0000],\n",
            "          [ 0.2084, -0.1057,  0.0373],\n",
            "          [ 0.1042, -0.2758, -0.1900]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1137, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0317, -0.0000],\n",
            "          [-0.2504,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000, -0.1554,  0.0403],\n",
            "          [ 0.2877, -0.2073,  0.0639]]],\n",
            "\n",
            "\n",
            "        [[[-0.2566, -0.0000,  0.2502],\n",
            "          [-0.2506,  0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000]]]], device='cuda:0',\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "049207c8"
      },
      "source": [
        "最后，使用pytorch的forward_pre_hooks会在每次forward之前应用这个pruning操作，需要指出的是当module被裁剪之后，它的每一个paramter都需要一个forward_pre_hooks来标识将被裁剪。当前我们只进行了conv1模块的weight裁剪，所以以下命令将只能看到一个hook。"
      ],
      "id": "049207c8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb2f406d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "392151d6-69e6-49a7-d807-52614b57fceb"
      },
      "source": [
        "print(module._forward_pre_hooks)"
      ],
      "id": "fb2f406d",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([(1, <torch.nn.utils.prune.PruningContainer object at 0x7fa8e3721350>)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3685b06"
      },
      "source": [
        "同样，我们还可以对conv1的bias进行L1unstructured的裁剪，和上述类似。"
      ],
      "id": "a3685b06"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c459a2ff"
      },
      "source": [
        "**迭代裁剪**\n",
        "\n",
        "单个module中的parameters是可以多次裁剪的，无非就是顺序的组合不同的mask和调用不同的pruning方法，结果是一致的，我们可以通过调用PruningContainer的compute_mask方法来实现在旧mask之上添加新的mask的逻辑。此时50%的kernel参数会被设置成0."
      ],
      "id": "c459a2ff"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a05cf384",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d69ac70d-31de-4829-a1b7-81f0f9821fb3"
      },
      "source": [
        "prune.ln_structured(module, name=\"weight\", amount=0.5, n=2, dim=0)\n",
        "print(module.weight)"
      ],
      "id": "a05cf384",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.0000,  0.0000, -0.3179],\n",
            "          [-0.0000,  0.0000, -0.0000],\n",
            "          [ 0.1922,  0.0000, -0.3047]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3054,  0.2523, -0.0000],\n",
            "          [ 0.0000,  0.3270, -0.1836],\n",
            "          [ 0.1698,  0.0000,  0.3102]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000],\n",
            "          [-0.0000,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.2566, -0.0000,  0.2502],\n",
            "          [-0.2506,  0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000]]]], device='cuda:0',\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a467750"
      },
      "source": [
        "这时候hook就会变成torch.nn.utils.prune.PruningContainer的类型，将会存储应用在weights参数上的所有prune操作。"
      ],
      "id": "9a467750"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cf5cec4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a7c6b2-d832-4f15-ceb9-31947eb719b6"
      },
      "source": [
        "for hook in module._forward_pre_hooks.values():\n",
        "    if hook._tensor_name == \"weight\":  # select out the correct hook\n",
        "        break\n",
        "\n",
        "print(list(hook))  # pruning history in the container"
      ],
      "id": "3cf5cec4",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<torch.nn.utils.prune.RandomUnstructured object at 0x7fa8e3765b90>, <torch.nn.utils.prune.RandomUnstructured object at 0x7fa8e3721c10>, <torch.nn.utils.prune.LnStructured object at 0x7fa8e3724490>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbbb4898"
      },
      "source": [
        "**序列化裁剪后的模型**\n",
        "所有的裁剪后的tensor都是存储在state_dict当中，这就非常便于我们做模型的序列化以及save操作。"
      ],
      "id": "fbbb4898"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86350f1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d00fa8-77b9-4fc8-87bc-1b9f8f54cbef"
      },
      "source": [
        "print(model.state_dict().keys())"
      ],
      "id": "86350f1d",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['conv1.bias', 'conv1.weight_orig', 'conv1.weight_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a38cd408"
      },
      "source": [
        "接下来我们会想，如何将pruning操作永久的作用于模型，而不保存类似weight_orig以及weight_mask 这样的Tensor，同时移除forward_pre_hook.\n",
        "prune中提供了remove操作, 需要注意的是，remove并不能undo裁剪的操作，使得什么都没发生过一样，仅仅是永久化，重新将weight赋值给module的源tensor."
      ],
      "id": "a38cd408"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c2941ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432434e0-978b-49c2-d65c-573fc3960d29"
      },
      "source": [
        "prune.remove(module, 'weight')\n",
        "print(list(module.named_parameters()))"
      ],
      "id": "6c2941ce",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('bias', Parameter containing:\n",
            "tensor([-0.2063, -0.0221,  0.0029,  0.3152,  0.2007,  0.1731], device='cuda:0',\n",
            "       requires_grad=True)), ('weight', Parameter containing:\n",
            "tensor([[[[-0.0000,  0.0000, -0.3179],\n",
            "          [-0.0000,  0.0000, -0.0000],\n",
            "          [ 0.1922,  0.0000, -0.3047]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3054,  0.2523, -0.0000],\n",
            "          [ 0.0000,  0.3270, -0.1836],\n",
            "          [ 0.1698,  0.0000,  0.3102]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000],\n",
            "          [-0.0000,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.2566, -0.0000,  0.2502],\n",
            "          [-0.2506,  0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000]]]], device='cuda:0', requires_grad=True))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cebc1b2"
      },
      "source": [
        "这时候我们会发现直接weight就是裁剪后的值，而weight_orig不见了。如果希望裁剪模型中的多个参数，可以遍历module然后重复上述操作即可。"
      ],
      "id": "9cebc1b2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85f7dc1b"
      },
      "source": [
        "**全局剪枝**\n",
        "\n",
        "相比之前的操作仅仅作用到指定的module，指定的参数，global pruning更加强大，可以通过如下配置来实现。"
      ],
      "id": "85f7dc1b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "843f13bd"
      },
      "source": [
        "model = LeNet()\n",
        "\n",
        "parameters_to_prune = (\n",
        "    (model.conv1, 'weight'),\n",
        "    (model.conv2, 'weight'),\n",
        "    (model.fc1, 'weight'),\n",
        "    (model.fc2, 'weight'),\n",
        "    (model.fc3, 'weight'),\n",
        ")\n",
        "\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.2,\n",
        ")"
      ],
      "id": "843f13bd",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0726bb19"
      },
      "source": [
        "这就非常方便，因为日常使用中我们往往追求一个全局的最终的一个效果，而不大关注特定的module的稀疏程度。"
      ],
      "id": "0726bb19"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ca565a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c0f9938-894f-499e-c652-dda470c53cc8"
      },
      "source": [
        "print(\n",
        "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.conv1.weight == 0))\n",
        "        / float(model.conv1.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.conv2.weight == 0))\n",
        "        / float(model.conv2.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.fc1.weight == 0))\n",
        "        / float(model.fc1.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in fc2.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.fc2.weight == 0))\n",
        "        / float(model.fc2.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in fc3.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.fc3.weight == 0))\n",
        "        / float(model.fc3.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Global sparsity: {:.2f}%\".format(\n",
        "        100. * float(\n",
        "            torch.sum(model.conv1.weight == 0)\n",
        "            + torch.sum(model.conv2.weight == 0)\n",
        "            + torch.sum(model.fc1.weight == 0)\n",
        "            + torch.sum(model.fc2.weight == 0)\n",
        "            + torch.sum(model.fc3.weight == 0)\n",
        "        )\n",
        "        / float(\n",
        "            model.conv1.weight.nelement()\n",
        "            + model.conv2.weight.nelement()\n",
        "            + model.fc1.weight.nelement()\n",
        "            + model.fc2.weight.nelement()\n",
        "            + model.fc3.weight.nelement()\n",
        "        )\n",
        "    )\n",
        ")"
      ],
      "id": "2ca565a9",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity in conv1.weight: 3.70%\n",
            "Sparsity in conv2.weight: 8.91%\n",
            "Sparsity in fc1.weight: 21.98%\n",
            "Sparsity in fc2.weight: 12.42%\n",
            "Sparsity in fc3.weight: 10.24%\n",
            "Global sparsity: 20.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2383598e"
      },
      "source": [
        "## 实战案例"
      ],
      "id": "2383598e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-OvNj6l1Qqo"
      },
      "source": [
        "步骤1：加载数据集"
      ],
      "id": "y-OvNj6l1Qqo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXDcsolZ1mY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c67f55a-11c9-46ca-8aa8-0cd2d5b52268"
      },
      "source": [
        "# Download dataset\n",
        "!gdown --id '1O6pFYd9aw1cZbry-NXk3k3tTXLVgssIg' --output food-11.zip\n",
        "# Unzip the files\n",
        "!unzip -q food-11.zip"
      ],
      "id": "UXDcsolZ1mY1",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1O6pFYd9aw1cZbry-NXk3k3tTXLVgssIg\n",
            "To: /content/food-11.zip\n",
            "100% 277M/277M [00:05<00:00, 50.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4TywnbX1sBO"
      },
      "source": [
        "步骤2：加载StudentNet"
      ],
      "id": "Q4TywnbX1sBO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unx-BFec1rau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79034ef5-52b6-4a56-e2cd-5db699ded130"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "# 运行之前的Architecture_Design文件\n",
        "!gdown --id '1-sSaAOk3vnmfZv8F4Vo_YhdrHkTNn7bh' --output \"Architecture_Design.ipynb\"\n",
        "%run \"Architecture_Design.ipynb\""
      ],
      "id": "Unx-BFec1rau",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-sSaAOk3vnmfZv8F4Vo_YhdrHkTNn7bh\n",
            "To: /content/Architecture_Design.ipynb\n",
            "\r  0% 0.00/7.62k [00:00<?, ?B/s]\r100% 7.62k/7.62k [00:00<00:00, 11.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crRYqAPD12b5"
      },
      "source": [
        "步骤3：执行代码"
      ],
      "id": "crRYqAPD12b5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d75804b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887d11ef-1489-4779-f2b2-246c35d7b949"
      },
      "source": [
        "import torchvision.models as models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# 加载训练好的StudentNet参数\n",
        "!gdown --id '12wtIa0WVRcpboQzhgRUJOpcXe23tgWUL' --output student_custom_small.bin\n",
        "class FoodDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, dir_path, transform, cuda=False):\n",
        "        self.cuda = cuda\n",
        "        self.transform = transform\n",
        "        self.x = []\n",
        "        self.y = []\n",
        "        img_names = sorted(os.listdir(dir_path))\n",
        "        for img_name in img_names:  # glob返回匹配到的所有文件的路径\n",
        "            img_path = os.path.join(dir_path, img_name)\n",
        "            label = int(img_name.split(\"_\")[0])\n",
        "\n",
        "            image = Image.open(img_path)\n",
        "            # Get File Descriptor\n",
        "            image_fp = image.fp\n",
        "            image.load()\n",
        "            # Close File Descriptor (or it'll reach OPEN_MAX)\n",
        "            image_fp.close()\n",
        "\n",
        "            self.x.append(image)\n",
        "            self.y.append(label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.transform(self.x[idx])\n",
        "        label = torch.torch.tensor(self.y[idx], dtype=torch.int64)\n",
        "        if self.cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "\n",
        "trainTransform = transforms.Compose([\n",
        "    transforms.RandomCrop(256, pad_if_needed=True, padding_mode='symmetric'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "testTransform = transforms.Compose([\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "def get_dataloader(dir_path='/data',mode='training', batch_size=32, cuda=False):\n",
        "\n",
        "    assert mode in ['training', 'testing', 'validation']\n",
        "\n",
        "    dataset = FoodDataset(\n",
        "        f'{dir_path}',\n",
        "        transform=trainTransform if mode == 'training' else testTransform, cuda=cuda)\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=(mode == 'training'))\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "def network_slimming(old_model, new_model):\n",
        "    old_params = old_model.state_dict()\n",
        "    new_params = new_model.state_dict()\n",
        "\n",
        "    # 只保留每一层中的部分卷积核\n",
        "    selected_idx = []\n",
        "    for i in range(8):  # 只对模型中CNN部分(8个Sequential)进行剪枝\n",
        "        gamma = old_params[f'cnn.{i}.1.weight']\n",
        "        new_dim = len(new_params[f'cnn.{i}.1.weight'])\n",
        "        ranking = torch.argsort(gamma, descending=True)\n",
        "        selected_idx.append(ranking[:new_dim])\n",
        "\n",
        "    now_processing = 1  # 当前在处理哪一个Sequential，索引为0的Sequential不需处理\n",
        "    for param_name, weights in old_params.items():\n",
        "        # 如果是CNN层，则根据gamma仅复制部分参数；如果是FC层或者该参数只有一个数字(例如batchnorm的tracenum等等)就直接全部复制\n",
        "        if param_name.startswith('cnn') and weights.size() != torch.Size([]) and now_processing != len(selected_idx):\n",
        "            # 当处理到Pointwise Convolution时，则代表正在处理的Sequential已处理完毕\n",
        "            if param_name.startswith(f'cnn.{now_processing}.3'):\n",
        "                now_processing += 1\n",
        "\n",
        "            # Pointwise Convolution的参数会受前一个Sequential和后一个Sequential剪枝情况的影响，因此需要特别处理\n",
        "            if param_name.endswith('3.weight'):\n",
        "                # 不需要删除最后一个Sequential中的Pointwise卷积核\n",
        "                if len(selected_idx) == now_processing:\n",
        "                    # selected_idx[now_processing-1]指当前Sequential中保留的通道的索引\n",
        "                    new_params[param_name] = weights[:,selected_idx[now_processing-1]]\n",
        "                # 除了最后一个Sequential，每个Sequential中卷积核的数量(输出通道数)都要和后一个Sequential匹配。\n",
        "                else:\n",
        "                    # Pointwise Convolution中Conv2d(x,y,1)的weight的形状是(y,x,1,1)\n",
        "                    # selected_idx[now_processing]指后一个Sequential中保留的通道的索引\n",
        "                    # selected_idx[now_processing-1]指当前Sequential中保留的通道的索引\n",
        "                    new_params[param_name] = weights[selected_idx[now_processing]][:,selected_idx[now_processing-1]]\n",
        "            else:\n",
        "                new_params[param_name] = weights[selected_idx[now_processing]]\n",
        "        else:\n",
        "            new_params[param_name] = weights\n",
        "    \n",
        "    # 返回新模型\n",
        "    new_model.load_state_dict(new_params)\n",
        "    return new_model\n",
        "\n",
        "\n",
        "def run_epoch(dataloader, new_net, optimizer, criterion, update=True):\n",
        "    total_num, total_hit, total_loss = 0, 0, 0\n",
        "    for now_step, batch_data in enumerate(dataloader):\n",
        "        # 清空 optimizer\n",
        "        optimizer.zero_grad()\n",
        "        # 获取数据\n",
        "        inputs, labels = batch_data\n",
        "            \n",
        "        logits = new_net(inputs)\n",
        "        loss = criterion(logits, labels)\n",
        "        if update:\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "        total_hit += torch.sum(torch.argmax(logits, dim=1) == labels).item()\n",
        "        total_num += len(inputs)\n",
        "        total_loss += loss.item() * len(inputs)\n",
        "\n",
        "    return total_loss / total_num, total_hit / total_num\n",
        "\n",
        "\n",
        "# config\n",
        "batch_size = 1\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "prune_count = 3\n",
        "prune_rate = 0.95\n",
        "finetune_epochs = 3\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # 加载数据\n",
        "    train_dataloader = get_dataloader('training', 'training', batch_size, cuda)\n",
        "    valid_dataloader = get_dataloader('validation', 'validation', batch_size, cuda)\n",
        "    print('Data Loaded')\n",
        "\n",
        "    # 加载网络\n",
        "    old_net = StudentNet()\n",
        "    if cuda:\n",
        "        old_net = old_net.cuda()\n",
        "    old_net.load_state_dict(torch.load('./student_custom_small.bin'))\n",
        "\n",
        "    # 开始剪枝并finetune：独立剪枝prune_count次，每次剪枝的剪枝率按prune_rate逐渐增大，剪枝后微调finetune_epochs个epoch\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(old_net.parameters(), lr=1e-3)\n",
        "\n",
        "    now_width_mult = 1\n",
        "    for i in range(prune_count):\n",
        "        now_width_mult *= prune_rate # 增大剪枝率\n",
        "        new_net = StudentNet(width_mult=now_width_mult)\n",
        "        if cuda:\n",
        "            new_net = new_net.cuda()\n",
        "        new_net = network_slimming(old_net, new_net)\n",
        "        now_best_acc = 0\n",
        "        for epoch in range(finetune_epochs):\n",
        "            new_net.train()\n",
        "            train_loss, train_acc = run_epoch(train_dataloader, new_net, optimizer, criterion, update=True)\n",
        "            new_net.eval()\n",
        "            valid_loss, valid_acc = run_epoch(valid_dataloader, new_net, optimizer, criterion, update=False)\n",
        "            # 每次剪枝时存下最好的model\n",
        "            if valid_acc > now_best_acc:\n",
        "                now_best_acc = valid_acc\n",
        "                torch.save(new_net.state_dict(), f'./pruned_{now_width_mult}_student_model.bin')\n",
        "            print('rate {:6.4f} epoch {:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(now_width_mult, \n",
        "                epoch, train_loss, train_acc, valid_loss, valid_acc))\n"
      ],
      "id": "7d75804b",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12wtIa0WVRcpboQzhgRUJOpcXe23tgWUL\n",
            "To: /content/student_custom_small.bin\n",
            "\r  0% 0.00/1.05M [00:00<?, ?B/s]\r100% 1.05M/1.05M [00:00<00:00, 16.5MB/s]\n",
            "Data Loaded\n",
            "rate 0.9500 epoch   0: train loss: 4.3217, acc 0.0990 valid loss: 1.9473, acc 0.6807\n",
            "rate 0.9500 epoch   1: train loss: 4.3158, acc 0.0994 valid loss: 2.0738, acc 0.6715\n",
            "rate 0.9500 epoch   2: train loss: 4.3032, acc 0.0986 valid loss: 2.3332, acc 0.6615\n",
            "rate 0.9025 epoch   0: train loss: 4.4357, acc 0.0990 valid loss: 2.5495, acc 0.5940\n",
            "rate 0.9025 epoch   1: train loss: 4.4380, acc 0.1011 valid loss: 2.0737, acc 0.6487\n",
            "rate 0.9025 epoch   2: train loss: 4.4153, acc 0.1036 valid loss: 2.1265, acc 0.6122\n",
            "rate 0.8574 epoch   0: train loss: 4.4611, acc 0.0944 valid loss: 2.2042, acc 0.5967\n",
            "rate 0.8574 epoch   1: train loss: 4.4358, acc 0.0899 valid loss: 1.8182, acc 0.6715\n",
            "rate 0.8574 epoch   2: train loss: 4.4884, acc 0.0928 valid loss: 1.8172, acc 0.6998\n"
          ]
        }
      ]
    }
  ]
}